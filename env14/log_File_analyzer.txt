import re
from collections import Counter
import os


LOG_PATTERN = re.compile(
    r'(?P<ip>\d+\.\d+\.\d+\.\d+)\s'       
    r'\S+\s\S+\s'                         
    r'\[(?P<datetime>[^\]]+)\]\s'         
    r'"(?P<method>\w+)\s(?P<url>[^"]+)\s[^"]+"\s'  
    r'(?P<status>\d+)\s(?P<size>\d+)'     
)

def parse_log_line(line):
    match = LOG_PATTERN.match(line)
    if match:
        return match.groupdict()
    return None

def analyze_log(file_path):
    if not os.path.exists(file_path):
        print(" Log file not found.")
        return

    ip_counter = Counter()
    url_counter = Counter()
    status_counter = Counter()

    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
        for line in file:
            data = parse_log_line(line)
            if data:
                ip_counter[data['ip']] += 1
                url_counter[data['url']] += 1
                status_counter[data['status']] += 1

    print("\n Log Summary:\n")

    print(" Top 5 IPs:")
    for ip, count in ip_counter.most_common(5):
        print(f"{ip}: {count} requests")

    print("\n Top 5 Requested URLs:")
    for url, count in url_counter.most_common(5):
        print(f"{url}: {count} times")

    print("\n Status Code Summary:")
    for status, count in status_counter.items():
        print(f"{status}: {count} times")

def main():
    print(" Log File Analyzer\n")
    file_path = input("Enter the path to access.log file: ").strip()
    analyze_log(file_path)

if __name__ == "__main__":
    main()
